# 笔记

## 缓存

### MyBatis中的一级缓存

当一个事务中发起多次同样的SQL查询时，后续将从MyBatis的缓存中读取。若非事务，则每次查询都会发起新的查询会话。

注意，一级缓存默认开启。若事务中两次相同之间涉及数据的修改，则后面几次读取的数据仍为缓存中修改前的数据，这将导致错误。解决方法：

- 可以通过配置`mybatis.configuration.local-cache-scope=statement`由默认的session改为statement，即关闭一级缓存。

### MyBatis中的二级缓存

MyBatis二级缓存中不同的 mapper, 即使操作的是同一张表，对应的缓存也是两块区域。当对同个namespace的mapper做增删改操作时，二级缓存就会清空（即使增删改的 SQL 没有改变数据， Mybatis 都会将同个命名空间下的二级缓存清空）。

MyBatis的二级缓存默认关闭。若要开启，需要：

- 相关mapper中新增`<cache></cache>`
- mapper中返回结果的实体类实现Serializable接口以序列化。当一个类需要保存起来，下次再还原成类时就需要序列化，或者需要远程传输，比如放到redis里，也需要序列化

MyBatis二级缓存缺点：

- 若涉及多读多写的场景则二级缓存近乎失效
- 二级缓存存在本地，若有多台服务器会发生数据不一致的问题

因此实际开发中很少使用MyBatis二级缓存。

### Spring内置缓存

Springboot本地缓存可以解决MyBatis二级缓存需要修改mapper的问题，但同样存在多个节点缓存不一致的问题，且缓存无过期策略，只能手动刷新。若要开启，需要：

- Spring Application上@EnableCaching

- 需要缓存的服务方法上@Cacheable

  > #### @Cacheable和@CachePut区别
  >
  > 一、相同点
  > 都是Spring的缓存注解
  >
  > 二、不同点
  > @Cacheable：只会执行一次，当标记在一个方法上时表示该方法是支持缓存的，Spring会在其被调用后将其返回值缓存起来，以保证下次利用同样的参数来执行该方法时可以直接从缓存中获取结果。
  > @CachePut标注的方法在执行前不会去检查缓存中是否存在之前执行过的结果，而是每次都会执行该方法，并将执行结果以键值对的形式存入指定的缓存中。

### Redis缓存

可通过配置`spring.cache.type=redis`参数，将Spring缓存存放到Redis上。使用 Redis 存放缓存解决了两个问题：

- 提高访问速度， mysql单机 QPS 约为 2000 ， redis 约 10 万
- 解决多节点共享缓存，机器重启也不会丢缓存数据

Redis 常用于放用户的登录信息，早期没有 redis 时，登录信息都放在 session中，应用一重启，登录就没有了，多节点 session 又是另一个头大的问题

### 缓存相关问题

#### 缓存击穿

一个热点的Key失效后，导致大量请求直接访问数据库

解决方案：

- 针对缓存过期失效问题：
  - 设置热点数据的预热策略，预先加载或刷新缓存中的数据
- 针对数据库查询问题：
  - 使用互斥锁或分布式锁来避免多个请求同时尝试加载缺失的数据，只有一个请求去加载数据，其他请求等待或返回旧数据或快速返回失败。

#### 缓存穿透

缓存穿透是指请求一个在数据库中也不存在的数据，因此无论如何都无法在缓存中找到该数据，每次请求都会导致数据库的查询操作。缓存穿透通常是由于恶意请求或错误的请求引起的，这些请求可能是故意构造的，以请求不存在的数据，导致缓存无法起到有效的过滤作用。

解决方案：

- 针对缓存不存在问题：

  - 对于不存在的数据，可以缓存一个特殊值，以避免不断地查询数据源。比如通过设置`spring.cache.redis.cache-null-values=true`允许Spring向Redis缓存null来表示数据库中不存在该数据，和代表实际数据的[]空列表相区分。

- 针对数据库查询问题：

  使用布隆过滤器（Bloom Filter）来快速判断请求的数据是否存在于数据库中，如果布隆过滤器认为数据不存在，就不会进一步查询数据库。

#### 缓存雪崩

和缓存击穿相似，由于短时间内，大量的Key失效，导致数据库压力剧增。缓存击穿&穿透的对象是单个缓存，而缓存雪崩的对象是海量缓存。

解决方案：

- 针对缓存失效问题：
  - 设置热点数据的预热策略，预先加载或刷新缓存中的数据
  - 使用合适的过期策略，常见的有：
    - TTL超时时间
    - LRU最近最少使用
    - LFU最近最不经常使用
    - FIFO先进先出
    - Random随机淘汰策略
    - 自适应过期策略：根据访问频率和数据的重要性动态调整数据的过期时间。热门数据可以设置较长的过期时间，冷门数据可以设置较短的过期时间。
  - 针对数据库查询问题：
    - 使用互斥锁或分布式锁来避免多个请求同时尝试加载缺失的数据，只有一个请求去加载数据，其他请求等待或返回旧数据或快速返回失败。

### 缓存在高并发场景中的生产问题分享

1. 场景：每天的会员数很多，百万级别，但每个会员一天只会有几次请求，一个会员信息在同一次请求中，会被用到多次，且会员信息较大

   - 问题：多次调用查询会员方法，组装信息多，多次访问数据库

     解决：使用本地缓存，1分钟有效

   - 问题： fullgc(stop the world）频繁，导致短时间内大量请求失败

     原因：因为会员信息是大对象，一分钟内会缓存大量缓存会员信息。造成JVM中新生代内存区域数据大量增加，触发GC。又因为缓存有效期为一分钟，不会将其回收，很快新生代又满了，再次触发GC。如此反复，一分钟内新生代内存区域发生大量GC，使JVM误认为缓存为重要信息而将其移入老生代内存区域。然而老年代很快也满了，这触发了fullgc，导致大量请求失败。

     解决：取消本地缓存，改为使用线程本地变量

## 分布锁

可能会发生超卖问题：假设库存为1，多个线程同时读到余票记录，都认为库存为1，就都往后去选座购票，最终导致超卖
解决方案：

- synchronized加锁->会导致吞吐量/TPS 变低，效率不高，且不适用于多节点环境（仍会超卖）
- **分布锁**

#### 实现方式

- Redis setnx

  **优点：**基于Redis实现的最基本的分布锁，实现简单

  **缺点：**线程执行时间超过锁时间，会导致锁失效，从而出现资源竞争错误

- 引入看门狗（守护线程）（项目主流使用此方案）

  定时查询锁剩余时间，当小于一定值时自动延时。使用守护线程的好处是会随主线程的结束而结束，所以不会出现一直重置而永不过期的问题

  **优点：**解决了线程执行时间超过锁时间导致锁失效的问题

  **缺点：**若Redis集群宕机，不同的请求在新老结点中都获取到了锁，还是会出现资源竞争错误

- Redis红锁

  一个分布式锁由多个节点共同维护，每个节点通过竞争获得锁。算法要求至少半数以上的节点成功获取锁才算锁获取成功。由于开销大，项目一般很少使用。

## 限流&降级&熔断

### 概念

- 限流：当系统资源不够，不足以应对大量请求，即系统资源与访问量出现矛盾的时候，我们为了保证有限的资源能够正常服务，因此对系统按照预设的规则进行流量限制或功能限制的一种方法。
- 降级：当我们的服务器压力剧增，为了保证核心功能的可用性 ，而选择性的降低一些功能的可用性，或者直接关闭该功能。

- 熔断：如果某个目标服务调用量太大或者响应时间太长，此时，熔断该服务的调用，当检测到目标服务情况好转则恢复调用。因此熔断是对服务的一种链路保护机制。

  原理：服务熔断是指调用方访问服务时通过断路器做代理进行访问，断路器会持续观察服务返回的成功、失败的状态，当失败超过设置的阈值时断路器打开，请求就不能真正地访问到服务了。

限流是做在被调用方，熔断是做在调用方

### 常见限流算法

- 静态窗口限流

- 滑动窗口限流

- 漏桶限流没有余票时，需要查库存才能知道没票，会影响性能，不如查令牌余量来得快

  漏桶可以看作是一个带有常量服务时间的单服务器队列，如果漏桶（包缓存）溢出，那么数据包会被丢弃。 在网络中，漏桶算法可以控制端口的流量输出速率，平滑网络上的突发流量，实现流量整形，从而为网络提供一个稳定的流量。把请求比作是水，水来了都先放进桶里，并以限定的速度出水，当水来得过猛而出水不够快时就会导致水直接溢出，即拒绝服务。

- 令牌桶限流

  令牌桶算法的原理是系统会以一个恒定的速度生成令牌并往桶里放入，如果桶满了，新放入的令牌会被丢弃。当请求需要被处理时，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。从原理上看，令牌桶算法和漏桶算法是相反的，一个“进水”，一个是“漏水”。

- 令牌大闸

  基于令牌桶限流算法，但是限制了令牌生成数量，当满了以后不再生成令牌。

  > **为什么要引入令牌大闸？**
  >
  > - 分布式锁和限流都不能解决机器人刷票的问题， 比如：1000 个请求抢票900个限流快速失败，另外100个有可能是同一个人在刷库。引入令牌可以根据用户标识对其单位时间内请求数量做出限制。
  > - 没有余票时，需要查库存才能知道没票，会影响性能，不如查令牌余量来得快

## Sentinel

### 限流

#### 不同的流控效果

- 快速失败

- WarmUp

  存在一个coldFactor因子，默认为 3。假设QPS阈值为100，预热时长是10秒，即请求 QPS 从100/coldFactor=33开始，经10秒预热时长才逐渐升至设定的100 QPS

- 排队等待

  让请求排队等待处理，若请求数量大于阈值，则等待超时时间。超过超时时间，请求失效。阈值类型必须设置为QPS，否则无效

#### 不同的流控模式

- 关联

  对目标的限流是有条件的，需要关联的资源限流时，目标才会限流。适用于两个资源关系密切的场景。比如下单的资源被限制，支付资源也将被限流。

- 链路

  对指定入口访问资源的请求进行限流

### 熔断

#### 不同的熔断策略

- 慢调用比例

  当请求数量大于最小请求数时，超过比例阈值的请求的时间超过最大RT时，触发熔断规则，熔断指定时长

- 异常比例、异常数

## Seata

### 四种事务模式

- AT 模式

  默认，简单，需要增加undo_log表，生成反向SQL ，性能高。回滚后，原来没数据的，现在还是没数据

- TCC 模式

  try confirm/cancel ，三个阶段的代码都得自己实现， Seata 只负责调度。对业务代码侵入性较强，必要时可能还要修改数据库（比如增加冻结字段）

- SAGA 模式

  长事务解决方案，需要程序员自己编写两阶段代码（AT 模式不需要写第二阶段confirm/cancel）。基于状态机来实现的，需要一个 JSON 文件，可异步执行

- XA模式

  XA 协议是由 X/Open 组织提出的分布式事务处理规范，基于数据库的XA协议来实现2PC 又称为XA方案，适用于强一致性的场景，比如金融、银行等。需要数据库本身支持XA协议，可以跨数据库。和其他三个模式不同，该模式不是每次操作都提交事务，而是最后提交一次。因此若有两个请求进入，后一个请求读取到的是第一个操作修改前的数据。



# 常见问题汇总

### generator代码生成器运行报错，找不到member中的枚举类

generator模块依赖member模块, member模块依赖common模块。所以先编译 common，再编译 member， 就可以执行generator了。

### 关于redis和mysql的一致性问题

mysql和redis的一致性，一般都是弱一致性，就是某个时间段，数据会不一致，但最终是一致的，比如余票查询，用户查的时候，列表从缓存里读，显示余票为1，但实际数据库可能是0了，但经过定时刷新缓存，最终缓存里也会变为0。

强一致性的话，几乎没法做，不适用，会有几个问题：

1. 每次有人买票，都要同时修改数据库和缓存，对于高并发抢票，就会去频繁的修改缓存，这就失去了缓存的意义，缓存应该是读多写少。
2. 比如缓存更新失败了，难道就不让用了？功能设计上，肯定是把缓存当成功能加强，而不是功能必须。缓存失败时，我们还是要能通过数据库来取数据，只不过为了防止并发过大，数据库撑不住，我们要加其它技术方案，比如限流、令牌、加锁等。
3. 一次购票中，我们想同时更新缓存和数据库，但没法做到同时，他们又不能加事务，总是有先后的，所以依然有可能出现用户查到的缓存数据和数据库不一致的情况。

所以，一般我们的用法就是弱一致性：数据读缓存，然后定期更新或条件更新缓存

### Seata的配置中心与Spring cloud的配置中心区别是?

在广义上来说,并无区别,只不过Spring cloud的配置中心仅是作用于它们自身的组件,而Seata的配置中心也是一样是作用于Seata自身.(注:Spring cloud的配置中心与Seata无关)。因此即使使用同一个配置中心，配置文件也是隔离的（可以理解为两个不同的项目）。注册中心同理。

### 最高并发数探测方法：

- 增加线程数，直到出现异常
- 增加线程数，直到平均响应时间超过预期的值（依项目而定，比如买票最多让用户等待 2 秒）

### 既然异步线程也能解决，为什么还要用RocketMQ，它是有更多功能吗？

- 异步是在本机运行的，MQ的收发可以不在同一机器上。比如购票的场景，用异步的话，接收订单和处理订单是在同一机器上，会抢资源；用MQ的话，就可以放在不同的机器上，比如接收订单的需要快速处理，可以配置10台机器，处理订单的不需要那么高的并发，只配置5台机器就可以了。
- 不用MQ时，假设库存10，有10个人同时抢票，只会有一个人拿到锁，另外9个人直接失败，也就是经过10人抢票后，只卖出去了一张票。而用MQ后，10个人是排队一个一个出票的，最终不会有剩余。

### 用了分布式锁之后性能一般，有什么优化方案或者代替方案吗？

用了锁后，会使卖票效率下降，也就是说卖票不会错，但卖得比较慢，我们可以将下单和出票使用MQ解耦，减少锁的占用时间，从而提高性能。